<html>
<head>
<title>Skybill software for traffic statistics processing</title>
</head>
<body>
<h1 align='center'>Skybill, your traffic counting</h1>
<p>Here comes the set of perl programs, most of them are plain Perl scripts to take information about traffic and put them into the database appropriately. The rest is a CGI ( <a href='http://fcgi-spawn.sf.net'>FastCGI</a> compatible ) program to show the results to the user.</p>
<p>The CGI output is shown on the <a href='http://skybill.vereshagin.org'>Skybill demo</a> page. That site is very &laquo;social&raquo; because the Skybill analyses the web server's access log there: it counts every visitor and shows his/her/its IP address to everyone, so in respect of your privacy I warn you about that before you click. There's a latency on traffic analisys so you should wait some minutes before you notice your IP address on that page as you may expect as a result.</p>
<p>Hardware requirements of the Skybill are very low: it passed several GB of traffic per day running via Pentium1 machine for years. Needless to say, the application tasks like web caching proxy and e-mail daemons did the load there among with Skybill, too.</p>
<p>Software is about to be <a href='http://sourceforge.net/projects/skybill/files/latest'>downloaded from SourceForge</a> or obtained via Git repositories ( see 'References' below ) as a work in process.</p>
<h2 align='center'>The purpose</h2>
<p>Originally, the software was intended for counting the traffic which was very expensive ( $0.1 per 1 MByte of data, no matter in or out ) because George Soross had underdeveloped the Internet in Russia (joke). It was a small LAN of an enterprise that was unsatisfied with every existing software to the date. This way, it was about to control the ISP statistics and local users' Internet consumption and was released as a v0.1 .</p>
<p>Some unexpected usage of the Skybill was found when the email viruses came on the scenes. Those were the times when we had news on the feeds like this one: &laquo;Spammers' software got skills to send itself via the particular deployment's ISP's relay&raquo;. It was obvious to look at the who is the most active sender on the port 25/tcp ( smtp ) to know what exactly workstation should be cured.</p>
<p>Clocks changed and things too, but people not.</p>
<p>Traffic was unchained for everyone with bandwidth limited only, so here we go about to know for every particular Internet user and server to know about the Internet connection's use by the case. Isn't it a next voluntary botnet like the Skype that use your paid full bandwidth without any excuse? How far it comes about your dedicated server's traffic? All of those things still cost money and here is how you can be more smart about those exepnses. Not to mention the additional care about your system's health.</p>
<p>To adopt for the conditions, changes were made about always changing IP address (thanks to my ISP) on behalf of your ISP and the ports being listened ( thanks to Skype, again ). But it is not mandatory part of the software as it is the part of the configuratino file which is written in Perl.</p>
<p>Scripts are the all about tweaking by hand, and several of them require the tweak.</p>
<h2 align='center'>What This Isn't</h2>
<p>You may want to look for the software to get the primary information about the traffic that passes through you hardware, like the network interfaces and routers, and software, like packet filters and application proxies.</p>
<p>Although you definitely must have one to get Skybill up and running, this is not the exact place to get them as it depends on your proprietary need. As an example you may want to use some scripts like ipacct2mysql from this package as ipacctd software is the one of them, but that program is too obvious to be considered as of any interest. To have a clue, you may ixquick or google for: ulogd if you need Linux' packet filter as the traffic information source, or ipacctd/ng_ipacct to take the same advantage for FreeBSD; it's just obvious thing to plug Skybill into any imagineable stuff in the world like the squid2mysql daemon, Cisco's netflow or Agnitum Outpost logs. Of course, any third-party scripts share for Skybill is appreciated.</p>
<h2 align='center'>How this works</h2>
<p>Before we dig into details, the key to understand this is: the Client nature of the traffic and the Server-generated nature of the bytes to count.</p>
<p>Client means the connection is established by ours. This means we need no information about our number of a port, only of remote. And vice-versa about Server-generated traffic: we need not no know about remote port's number, but the our port number is of a definite interest.</p>
<div align='center'><img border='0'
	src='./img/skybill03.png'
/><br
/>Figure 1. Traffic processing by the cron scripts</div>
<p>
<p>The program knows about the reason to separate from the config, the lib/Skybill/Config.pm . The packaged default is all about to take this information from the system's ifconfig/ipconfig and netstat commands when needed. You may want to keep those data manually enetered and persistent on a server.</p>
<p>On the left of the scheme, the traffic information source puts the data into the 'raw' table. The time granularity for those data is once per second, and there should be no any duplicates on src:port and dest:port. To increase the performance, the data is stored as 4-byte sequences (integers), as all of the IPv4 addresses are them, initially.</p>
<p>In the case if you have several statistics sources like ipacct and squid it is convinient to observe the primary key violation exception throw into the mail from cron because that means not every appropriate packet is transparently proxified by squid. In the case it is not the wanted behavior you may want to disable the key constraint on the 'raw' table in favor of index instead.</p>
<p>It is highly necessary that data to be processed sequentially from raw to clients and servers data before the next such a process is launched again so it is where you must find a balance between data collection speed and data integrity. I find it useful to launch cliserv script every few minutes, but YMMV.</p>
<p>It worths to note that besides unmentioning about the unneeded port number on the clients and servers data, the timestamp field shows the last time when the particular client was using the particular server. So it may be useful as a source for the various daytime charts about particular clients and servers utilization.</p>
<p>After the clients and servers tables are fullfilled, the data are aggregated into the details_daily table with no sense about ports numbers, i. e. about relationship between the particular hosts. This was useful for LAN routing/NAT service users monitoring but still helps for one host only.</p>
<p>The details_monthly has almost the same prupose as the details_daily, except that it keeps data about every particular IP addresses one per a row and keeps the data summarized for the whole months. The src/dest field is an information about the particular data flow direction.</p>
<p>As for cliserv_summary: it is an optional data to make the shoulders on a demo &laquo;t-shirt&raquo; layout for a quick reference on what's up. It is highly advised to enhance this feature to suit your particular needs.</p>
<p>The 'daily' table contains the data about the daily traffic amount and is updated every minute.</p>
<h2 align='center'>FCGI::Spawn</h2>
<p>CGI program was made compatible with <a href='http://fcgi-spawn.sf.net'>FCGI::Spawn</a> &mdash; the FastCGI protocol multiprocess server for CGI-like applications forking capable of parallel serving several applications at the same time and with features like processes persistence, max_requests limit on every particular process fork and the copy-on-write kernel facility utilization that saves memory on the server. Another optional feature used from FCGI::Spawn is its xinc() cache  for XSLT processor object which is entirely depends on the xsl file(s) and gonna be parsed and compiled as a data representation technique on every request in a vanilla CGI environment which makes much resource consumption. The xinc itself is a new feature in the FCGI::Spawn v0.16 .</p>
<h2 align='center'>Purpose modifications</h2>
<p>There is a significant purpose change between v0.1 and v0.2 . But the Skybill is still can be found useful to account the served LAN with the following assumptions in sight:
<ul>
<li>The core of the program is the data flow being split into the two kinds of traffic and union of data flow thereafter. You may never find Skybill useful for any other concept.</li>
<li>The data split to the 'incoming', or 'clients-originated', and 'outgoing', or 'servers-originated', is conditional and depends on your particular need. To give a clue: It is not much hard to adopt the software because it is all about 2 sql statements to split data in the cliserv script and plus 2 of them in the details_daily script. The only limitation is: you will need to count only one direction of the traffic to count it by LAN clients, as it is done in the v0.1 for the incoming direction. Version 0.2 counts the both directions.</p>
<p>As of v0.1, the traffic limitation per LAN user was accomplished in terms of the individual monthly amount setting. That included limitation CGI admin interface featuring 'rest hours' ( of the day ) setting  when the firewall limitation differs.  This is not (yet ) the case in v0.2 .</p>
<h2 align='center'>Installation</h2>
<h3 align='center'>Prerequisites</h3>
<p>First of all, you must decide on how you will get network statistics. If this is the aggregated packets statistics like netflow or ipacctd, then you may use the ipacct2mysql script. If this is something like the squid2mysql that puts each and every request on the sql table, it is obvious that you should write a script to make the statistics aggregated no more frequently than per every second. This is done by executing SQL clause like 'INSERT INTO raw SELECT ... from raw_squid GROUP BY ts' and DELETE'ing the all of the have-just-INSERT'ed data from that constraintless table. This is to be included into the 'every minute' chain of scripts, something like the ipacct_min.sh.</p>
<p>There is no any special need for the software, despite the dependencies list is long, all of them should be met in your system. Minimal software versions are: perl-5.6, mysql-4.0+ ( 4.1+ as of v0.2 ). Necessary perl modules are: DBI ( and DBD::mysql ), CGI (although FCGI::Spawn with its CGI.pm.patch is highly recommended ) and XML::LibXSLT which is needed for a web interface only.<br />
One may notice things like Net::Interface on a Config.pm. This is to adopt to the always changing network conditions and may not be the case for you. Another thing to pay attention to is: shell scripts tweak, at least the BIN_PREFIX path.</p>
<h3 align='center'>The rest</h3>
<p>Cron scripts are these ( 'ipacct_' prefix is typically assumed ):
<ul>
<li>_min.sh, edited by you according to your statistics collection method, to be executed every minute, or the most frequently of your wish, but no more frequently than every few seconds;
	<ul>This includes:
	<li>scripts like ipacct2mysql to put statistics summarized per several ( 60 ) seconds to the 'raw' table from the data source like the ipacctd;</li>
	<li>scripts like squid-mysql2ipacct from v0.1 to aggregate statistics from per log entry ( like squid2mysql does ) to the per several seconds to put to the 'raw' table;</li>
	</ul>
</li>
<li>_10min.sh, edited same way, executed several times less frequently than the _min;
	<ul>This includes:
	<li>cliserv to aggregate daily traffic as a client- or server-originated, keeping its last appearance time of day;</li>
	<li>details to aggregate daily traffic at a source-to destination IP address, and monthly traffic per every IP address and flow direction;</li>
	<li>cliserv_summary and probably more to make the shoulders on a CGI's &laquo;t-shirt&raquo;.</li>
	</ul>
</li>
<li>_everyday, to wipe old daily statistics, to be executed daily.</li>
</ul>
</p>
<p>Config.pm variables are mostly self-explanatory; typically you can grep the sources to know the what are they all about. The necessary things to change after you copy the sample Config.pm.sample to Config.pm are database connection variables.</p>
<p>To know that everything is correct, you should calculate a daily bytes sum for each stage of data flow process. It should be all the same. If for some day it is different thus something is wrong on sql statements.</p>
<h3 align='center'>More on geolocation</h3>
<p>Skybill's CGI ( FCGI::Spawn-compatible ) frontend detects language detection based on the geolocation.</p>
<p>The common practice for country location is application-based. This is not the case for the Skybill: it use the COUNTRY_CODE environment variable to choose the appropriate xsl template. Such a variable is obvious to be set by the web server itself ( like the fastcgi_param on the Nginx.conf ) and is my proposal as a convinient standard way to pass the geo data from web server to the application.</p>
<p>There are lots of such a geolocation data sources including free ones, to be used for your web server. You may change the CGI program anyway if you should prefer old way: to take geo data from your database in an application.</p>
<h2 align='center'>References</h2>
Project's Git repository is at <a href='http://github.com/petr999/skybill'>GitHub</a> and the <a href=''>latest development version</a> is available via SourceForge's Git <a href='http://skybill.git.sourceforge.net/git/gitweb-index.cgi'>repository</a>, too.
<h2 align='center'>Acknowledgements</h2>
<p>Thanks to: Skyriver Studios for test case and Roman Palagin for ipacctd.</p>
<p>Bugs and TODOs are tracked at Peter Vereshagin's <a href='http://bugs.vereshagin.org/buglist.cgi?query_format=advanced;product=Skybill%20traffic%20accounting%2Fnetwork%20monitoring'>Bugzilla</a>. License is <a href='http://www.freebsd.org/copyright/freebsd-license.html'>BSD</a>.
</p>
</body>
</html>
